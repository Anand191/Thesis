\chapter{Conclusions and Future Work} \label{Chapter:conclusion}%
In this thesis, I have introduced the concept of attentive guidance (AG) which is a way of biasing a seq2seq model to learn in a systematic fashion. This form of systematic compositionality is at the core of how humans learn \citep{marcus2003algebraic} and gives them the ability to one shot generalize to new concepts \citep{Lake2016}. Thanks to AG, I test the claim that when explicitly forced to focus on the primitives building up a complex expression, seq2seq models without additional modification are able to generalize to new concepts. The results presented on two datasets, one which exhibits hierarchical and functional compositionality and another which is built using the production rules of a PCFG, substantiate the aforementioned claim. The role of perfect attention in a compositional learner has further been substantiated by attempting to solve a new dataset introduced in this thesis. The dataset has been built on the concept of subregular language hierarchy (section \ref{flt:sh}) and experiments were carried out using vanilla seq2seq model and a hard guidance model. It was observed from the results obtained on this dataset that while vanilla seq2seq can solve the decision task, it failed on the more difficult search task, whereas hard guided model succeeded on both. This warrants additional investigation for effectiveness of hard guidance in languages which are higher up in the polynomial hierarchy \citep{arora2009computational}. 

However, AG comes with its own set of pitfalls and they become evident as I move towards more difficult forms of zero shot generalization (longer samples in case of lookup tables and symbol rewriting tasks). This is in contrast to the performance that is seen with hard guidance, i.e.\ when we explicitly provide the target attention vector as input to the decoder. This presents a case for using alternative paradigms for learning the guidance, as compared to supervised learning. The decoder can be tasked with finding the ideal attention vectors from a controlled search space of possible attention vectors in a reinforcement learning \citep{sutton2018reinforcement} setting. Similarly, the pondering that is currently \lq mocked\rq{} in some cases (sections \ref{lt:ponder} \ref{mt:ponder})by AG, can be learned and this would make the decoder more adaptive to different sequence lengths or unseen input prompts by allowing it to ponder over them for more steps. In the current architectural setup, the burden of learning the attention falls on the decoder while the encoder remains the same as in the case of a vanilla seq2seq model. Another possible area of investigation could be tasking the encoder with presenting the information to the decoder in the most efficient fashion or by allowing dynamic encoder outputs based on an on-line loss feedback from the decoder at each step. 

Finally, revisiting the information retrieval viewpoint presented by \cite{Vaswani2017}, it can be argued that AG leads to compositional solutions via efficient information retrieval,  i.e.\ giving the decoder access to the most informative encoder outputs at each step. However, another salient feature of human beings is their capacity for learning rich representation and then transferring that knowledge to new concepts \citep{Lake2015}. Therefore, a parallel line of research could be creating latent space representations in encoder decoder models,  which are more in sync with the structure of the data. Recently, \cite{Nickel2017} proposed embedding hierarchical data such as complex networks into hyperbolic (Poincar\'e ball) spaces to better capture the tree like structure in the data. They showed that Poincar\'e embeddings outperform Euclidean embeddings on data exhibiting latent hierarchies. Capturing the latent hierarchies of a data in a non-euclidean latent space presents an interesting line of research for (compositional) representation learning.
