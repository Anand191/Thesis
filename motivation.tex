\chapter{Motivation} \label{Chapter:motivation}

What I am actually looking at -  Compositionality, Problems of RNN- SCAN, Lookup Tables. Why should it be compositional.

Pondering should be here as well.

Split it into background-technical and motivation-CH, Compositionality, Pondering etc.

\section{Systematic Compositionality}

\section{Attention}

\subsection{Attention in Humans}
Attention from a cognitive neuroscience perspective. Attentional blink

\subsection{Se2Seq with Attention}
It was shown by Cho et al. \cite{W14-4012} that the performance of a basic encoder-decoder models as explained in \ref{background:s2s} is inversely related to the increase in length of the input sentence. Therefore in lines with concepts of the selective attention and attentional blink in human beings, Badhanau et al. \cite{bibid} and later Luong et al. \cite{bibid} showed that soft selection from source states where most relevant information can be assumed to be concentrated during a particular translation step in NMT leads to improved performance.

Also cover this from a key-value pair pov.

\section{Formal Language Theory}
The field of formal language theory (FLT) concerns itself with the syntactic structure of natural language without much emphasis on the semantics. More precisely a formal language $L$ is a sequence of strings with the constituent units/words/morphemes taken from a finite vocabulary $\Sigma$. It is more apt to define the concept of a formal grammar before proceeding further. A formal grammar $G$ is a quadruple $<\Sigma, NT, S, R>$ where $\Sigma$ is the vocabulary as previously defined, $NT$ is the set of non-terminals, $S$ the start symbol and $R$ the set of rules. A rule can be expressed as $a \rightarrow b$ and can be understood as a substitution of $a$ with $b$ with $a, b$ coming from $\Sigma$ and/or $NT$. Now a formal language $L(G)$ can be defined as the set of all strings  \textit{generated} by grammar $G$ such that the string consists of morphemes only from $\Sigma$, and has been generated by a finite set of rule ($R$) application after starting from $S$.

\subsection{Chomsky Hierarchy}\label{flt:ch}
\blindtext

\subsection{Subregular Hierarchy}\label{flt:sh}
The simplest class of languages encountered in section \ref{flt:ch} were regular languages that can be described using a FSA. If a language can be described by a mechanism even simpler than the FSA then it is a subregular language. While far from the expressive capabilities of regular languages which in turn are the least expressive class in the Chomsky hierarchy, subregular languages provide an excellent benchmark to test basic concept learning and pattern recognition ability of any intelligent system.

\subparagraph{Strictly local languages} We start with a string $w$ and we are given a lookup table of k-adjacent characters known as \textit{k-factors}, drawn from a particular language. The lookup table therefore serves the role of the language description. A language is \textit{k}-local, if every \textit{k}-factor seen by a \textit{scanner} with a windows of size $k$ sliding over the string $w$, is included in the aforementioned lookup-table.  

\subparagraph{Locally k-testable languages} Instead of sliding a scanner over \textit{k}-factors we consider all the \textit{k}-factors to be atomic and build \textit{k}-expression out of them using \textit{propositional logic}. This language description is locally k-testable. As in the case of strictly local languages, scanner won window size $K$ slides over the string and records for every k-factor in vocabulary it's occurrence or nonoccurence in the string. The output of this scanner is then fed to a boolean network which verifies the k-expressions.  


\section{Pondering}



